{
  "flow_runs": [
    {
      "run_id": "5992c219-66a4-4c28-beab-abafcff2a13c_0",
      "status": "Failed",
      "error": {
        "message": "OpenAI API hits BadRequestError: Error code: 400 - {'error': {'message': '3 validation errors for Request\\nbody -> stop\\n  none is not an allowed value (type=type_error.none.not_allowed)\\nbody -> logit_bias\\n  extra fields not permitted (type=value_error.extra)\\nbody -> response_format\\n  extra fields not permitted (type=value_error.extra)', 'type': 'invalid_request_error', 'param': None, 'code': None}} [Error reference: https://platform.openai.com/docs/guides/error-codes/api-errors]",
        "messageFormat": "",
        "messageParameters": {},
        "referenceCode": "Tool/promptflow.tools.aoai",
        "code": "UserError",
        "innerError": {
          "code": "OpenAIError",
          "innerError": {
            "code": "BadRequestError",
            "innerError": null
          }
        },
        "debugInfo": {
          "type": "WrappedOpenAIError",
          "message": "OpenAI API hits BadRequestError: Error code: 400 - {'error': {'message': '3 validation errors for Request\\nbody -> stop\\n  none is not an allowed value (type=type_error.none.not_allowed)\\nbody -> logit_bias\\n  extra fields not permitted (type=value_error.extra)\\nbody -> response_format\\n  extra fields not permitted (type=value_error.extra)', 'type': 'invalid_request_error', 'param': None, 'code': None}} [Error reference: https://platform.openai.com/docs/guides/error-codes/api-errors]",
          "stackTrace": "\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\executor\\flow_executor.py\", line 883, in _exec\n    output, aggregation_inputs = self._exec_inner_with_trace(\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\executor\\flow_executor.py\", line 790, in _exec_inner_with_trace\n    output, aggregation_inputs = self._exec_inner(\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\executor\\flow_executor.py\", line 819, in _exec_inner\n    output, nodes_outputs = self._traverse_nodes(inputs, context)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\executor\\flow_executor.py\", line 979, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context, inputs, batch_nodes)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\executor\\flow_executor.py\", line 1005, in _submit_to_scheduler\n    ).execute(self._line_timeout_sec)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\executor\\_flow_nodes_scheduler.py\", line 89, in execute\n    raise e\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\executor\\_flow_nodes_scheduler.py\", line 72, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\executor\\_flow_nodes_scheduler.py\", line 113, in _collect_outputs\n    each_node_result = each_future.result()\n  File \"C:\\git\\pfmisc\\.conda\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n    return self.__get_result()\n  File \"C:\\git\\pfmisc\\.conda\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"C:\\git\\pfmisc\\.conda\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\executor\\_flow_nodes_scheduler.py\", line 134, in _exec_single_node_in_thread\n    result = context.invoke_tool(node, f, kwargs=kwargs)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\_core\\flow_execution_context.py\", line 88, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f, kwargs)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\_core\\flow_execution_context.py\", line 196, in _invoke_tool_with_timer\n    raise e\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\_core\\flow_execution_context.py\", line 190, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\_core\\tracer.py\", line 528, in wrapped\n    output = func(*args, **kwargs)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\tools\\common.py\", line 222, in wrapper\n    raise WrappedOpenAIError(e)\n",
          "innerException": {
            "type": "BadRequestError",
            "message": "Error code: 400 - {'error': {'message': '3 validation errors for Request\\nbody -> stop\\n  none is not an allowed value (type=type_error.none.not_allowed)\\nbody -> logit_bias\\n  extra fields not permitted (type=value_error.extra)\\nbody -> response_format\\n  extra fields not permitted (type=value_error.extra)', 'type': 'invalid_request_error', 'param': None, 'code': None}}",
            "stackTrace": "Traceback (most recent call last):\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\tools\\common.py\", line 207, in wrapper\n    return func(*args, **kwargs)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\tools\\aoai.py\", line 157, in chat\n    completion = self._client.chat.completions.create(**params)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\_core\\openai_injector.py\", line 88, in wrapper\n    return f(*args, **kwargs)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\_core\\tracer.py\", line 528, in wrapped\n    output = func(*args, **kwargs)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n    return func(*args, **kwargs)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 667, in create\n    return self._post(\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\openai\\_base_client.py\", line 1208, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\openai\\_base_client.py\", line 897, in request\n    return self._request(\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\openai\\_base_client.py\", line 988, in _request\n    raise self._make_status_error_from_response(err.response) from None\n",
            "innerException": null
          }
        }
      },
      "inputs": {
        "topic": "chickens",
        "outputjoke": "What did the chicken cross the road? .. to get to the other side! "
      },
      "output": null,
      "metrics": null,
      "request": null,
      "parent_run_id": "5992c219-66a4-4c28-beab-abafcff2a13c",
      "root_run_id": "5992c219-66a4-4c28-beab-abafcff2a13c",
      "source_run_id": null,
      "flow_id": "template_eval_flow",
      "start_time": "2024-03-23T09:08:59.692950Z",
      "end_time": "2024-03-23T09:09:01.562100Z",
      "index": 0,
      "api_calls": [
        {
          "name": "flow",
          "node_name": "flow",
          "type": "Flow",
          "start_time": 1711145339.69295,
          "end_time": 1711145341.5621,
          "children": [
            {
              "name": "AzureOpenAI.chat",
              "type": "Tool",
              "inputs": {
                "prompt": "System: \nYou are a dad jokes expert, you will review dad jokes against a given topic and assess how funny and on topic the joke is.\n\nYou will give the joke 1 to 5 star score based on comedic value: 1 is eh, 5 is super funny.\nAnd you will give the joke 1 to 5 star score based on joke relevance to topic, where 1 is remotely on topic, and 5 very on topic.\n\nThis rating value should always be an integer between 1 and 5. So the rating produced should be 1 or 2 or 3 or 4 or 5.\n\nHere is an example:\n\ntopic: chicken\njoke: why did the chicken cross the rod, to get to the other side\n\nExpected result in json format: \n\n{\n\"comedic_value\": 4,\n\"comedic_relevance\": 5\n}\n\n\nhere is the user input:\n\ntopic:  {{topic}}\njoke: {{joke}}",
                "deployment_name": "gpt-4-32k-default-aueast",
                "temperature": 0.1,
                "top_p": 1,
                "max_tokens": 50,
                "presence_penalty": 0,
                "frequency_penalty": 0,
                "joke": "chickens",
                "topic": "What did the chicken cross the road? .. to get to the other side! "
              },
              "output": "{\n\"comedic_value\": 1,\n\"comedic_relevance\": 1\n}",
              "start_time": 1711145339.696947,
              "end_time": 1711145341.098032,
              "error": null,
              "children": [
                {
                  "name": "openai.resources.chat.completions.Completions.create",
                  "type": "LLM",
                  "inputs": {
                    "model": "gpt-4-32k-default-aueast",
                    "messages": [
                      {
                        "role": "system",
                        "content": "You are a dad jokes expert, you will review dad jokes against a given topic and assess how funny and on topic the joke is.\n\nYou will give the joke 1 to 5 star score based on comedic value: 1 is eh, 5 is super funny.\nAnd you will give the joke 1 to 5 star score based on joke relevance to topic, where 1 is remotely on topic, and 5 very on topic.\n\nThis rating value should always be an integer between 1 and 5. So the rating produced should be 1 or 2 or 3 or 4 or 5.\n\nHere is an example:\n\ntopic: chicken\njoke: why did the chicken cross the rod, to get to the other side\n\nExpected result in json format: \n\n{\n\"comedic_value\": 4,\n\"comedic_relevance\": 5\n}\n\n\nhere is the user input:\n\ntopic:  What did the chicken cross the road? .. to get to the other side! \njoke: chickens"
                      }
                    ],
                    "temperature": 0.1,
                    "top_p": 1,
                    "n": 1,
                    "stream": false,
                    "stop": null,
                    "max_tokens": 50,
                    "presence_penalty": 0,
                    "frequency_penalty": 0,
                    "logit_bias": {},
                    "user": "",
                    "response_format": null
                  },
                  "output": {
                    "id": "chatcmpl-95rf1PYYiDGQJaqiBi5EVgEirMhH1",
                    "choices": [
                      {
                        "finish_reason": "stop",
                        "index": 0,
                        "logprobs": null,
                        "message": {
                          "content": "{\n\"comedic_value\": 1,\n\"comedic_relevance\": 1\n}",
                          "role": "assistant",
                          "function_call": null,
                          "tool_calls": null
                        },
                        "content_filter_results": {
                          "hate": {
                            "filtered": false,
                            "severity": "safe"
                          },
                          "self_harm": {
                            "filtered": false,
                            "severity": "safe"
                          },
                          "sexual": {
                            "filtered": false,
                            "severity": "safe"
                          },
                          "violence": {
                            "filtered": false,
                            "severity": "safe"
                          }
                        }
                      }
                    ],
                    "created": 1711184939,
                    "model": "gpt-4-32k",
                    "object": "chat.completion",
                    "system_fingerprint": null,
                    "usage": {
                      "completion_tokens": 19,
                      "prompt_tokens": 216,
                      "total_tokens": 235
                    },
                    "prompt_filter_results": [
                      {
                        "prompt_index": 0,
                        "content_filter_results": {
                          "hate": {
                            "filtered": false,
                            "severity": "safe"
                          },
                          "self_harm": {
                            "filtered": false,
                            "severity": "safe"
                          },
                          "sexual": {
                            "filtered": false,
                            "severity": "safe"
                          },
                          "violence": {
                            "filtered": false,
                            "severity": "safe"
                          }
                        }
                      }
                    ]
                  },
                  "start_time": 1711145339.700947,
                  "end_time": 1711145341.097014,
                  "error": null,
                  "children": [],
                  "node_name": null,
                  "parent_id": "772a551a-16dd-4e5a-91b7-7525c7c4014c",
                  "id": "b241652b-9007-451d-a943-3c3eaf2e6364",
                  "system_metrics": {
                    "completion_tokens": 19,
                    "prompt_tokens": 216,
                    "total_tokens": 235
                  }
                }
              ],
              "node_name": "joke_score",
              "parent_id": "",
              "id": "772a551a-16dd-4e5a-91b7-7525c7c4014c",
              "system_metrics": {
                "completion_tokens": 19,
                "prompt_tokens": 216,
                "total_tokens": 235
              }
            },
            {
              "name": "line_process",
              "type": "Tool",
              "inputs": {
                "jokescore": "{\n\"comedic_value\": 1,\n\"comedic_relevance\": 1\n}"
              },
              "output": {
                "comedic_value": 1,
                "comedic_value_pass_rate": 0,
                "comedic_relevance": 1,
                "comedic_relevance_pass_rate": 0
              },
              "start_time": 1711145341.110026,
              "end_time": 1711145341.114015,
              "error": null,
              "children": [],
              "node_name": "line_process",
              "parent_id": "",
              "id": "d488766e-dd47-469f-8004-12ac04ffb60a",
              "system_metrics": {}
            },
            {
              "name": "AzureOpenAI.chat",
              "type": "Tool",
              "inputs": {
                "prompt": "System:\nensure the following is a correct json format: \n\nuser input:\n{{input}}",
                "deployment_name": "gpt-4-vision-aueast",
                "temperature": 0,
                "top_p": 1,
                "max_tokens": 50,
                "presence_penalty": 0,
                "frequency_penalty": 0,
                "input": "{\n\"comedic_value\": 1,\n\"comedic_relevance\": 1\n}"
              },
              "output": null,
              "start_time": 1711145341.118075,
              "end_time": 1711145341.29981,
              "error": {
                "message": "OpenAI API hits BadRequestError: Error code: 400 - {'error': {'message': '3 validation errors for Request\\nbody -> stop\\n  none is not an allowed value (type=type_error.none.not_allowed)\\nbody -> logit_bias\\n  extra fields not permitted (type=value_error.extra)\\nbody -> response_format\\n  extra fields not permitted (type=value_error.extra)', 'type': 'invalid_request_error', 'param': None, 'code': None}} [Error reference: https://platform.openai.com/docs/guides/error-codes/api-errors]",
                "type": "WrappedOpenAIError"
              },
              "children": [
                {
                  "name": "openai.resources.chat.completions.Completions.create",
                  "type": "LLM",
                  "inputs": {
                    "model": "gpt-4-vision-aueast",
                    "messages": [
                      {
                        "role": "system",
                        "content": "ensure the following is a correct json format: \n\nuser input:\n{\n\"comedic_value\": 1,\n\"comedic_relevance\": 1\n}"
                      }
                    ],
                    "temperature": 0,
                    "top_p": 1,
                    "n": 1,
                    "stream": false,
                    "stop": null,
                    "max_tokens": 50,
                    "presence_penalty": 0,
                    "frequency_penalty": 0,
                    "logit_bias": {},
                    "user": "",
                    "response_format": null
                  },
                  "output": null,
                  "start_time": 1711145341.125013,
                  "end_time": 1711145341.298813,
                  "error": {
                    "message": "Error code: 400 - {'error': {'message': '3 validation errors for Request\\nbody -> stop\\n  none is not an allowed value (type=type_error.none.not_allowed)\\nbody -> logit_bias\\n  extra fields not permitted (type=value_error.extra)\\nbody -> response_format\\n  extra fields not permitted (type=value_error.extra)', 'type': 'invalid_request_error', 'param': None, 'code': None}}",
                    "type": "BadRequestError"
                  },
                  "children": [],
                  "node_name": null,
                  "parent_id": "c1006179-6681-4ff1-84c6-c139122c8cd3",
                  "id": "ec9f2363-6730-471d-979b-eec515a7851a",
                  "system_metrics": {}
                }
              ],
              "node_name": "ensure_json",
              "parent_id": "",
              "id": "c1006179-6681-4ff1-84c6-c139122c8cd3",
              "system_metrics": {}
            }
          ],
          "system_metrics": {
            "duration": 1.86915,
            "prompt_tokens": 216,
            "completion_tokens": 19,
            "total_tokens": 235
          },
          "inputs": {
            "topic": "chickens",
            "outputjoke": "What did the chicken cross the road? .. to get to the other side! "
          },
          "output": null,
          "error": {
            "message": "OpenAI API hits BadRequestError: Error code: 400 - {'error': {'message': '3 validation errors for Request\\nbody -> stop\\n  none is not an allowed value (type=type_error.none.not_allowed)\\nbody -> logit_bias\\n  extra fields not permitted (type=value_error.extra)\\nbody -> response_format\\n  extra fields not permitted (type=value_error.extra)', 'type': 'invalid_request_error', 'param': None, 'code': None}} [Error reference: https://platform.openai.com/docs/guides/error-codes/api-errors]",
            "messageFormat": "",
            "messageParameters": {},
            "referenceCode": "Tool/promptflow.tools.aoai",
            "code": "UserError",
            "innerError": {
              "code": "OpenAIError",
              "innerError": {
                "code": "BadRequestError",
                "innerError": null
              }
            },
            "debugInfo": {
              "type": "WrappedOpenAIError",
              "message": "OpenAI API hits BadRequestError: Error code: 400 - {'error': {'message': '3 validation errors for Request\\nbody -> stop\\n  none is not an allowed value (type=type_error.none.not_allowed)\\nbody -> logit_bias\\n  extra fields not permitted (type=value_error.extra)\\nbody -> response_format\\n  extra fields not permitted (type=value_error.extra)', 'type': 'invalid_request_error', 'param': None, 'code': None}} [Error reference: https://platform.openai.com/docs/guides/error-codes/api-errors]",
              "stackTrace": "\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\executor\\flow_executor.py\", line 883, in _exec\n    output, aggregation_inputs = self._exec_inner_with_trace(\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\executor\\flow_executor.py\", line 790, in _exec_inner_with_trace\n    output, aggregation_inputs = self._exec_inner(\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\executor\\flow_executor.py\", line 819, in _exec_inner\n    output, nodes_outputs = self._traverse_nodes(inputs, context)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\executor\\flow_executor.py\", line 979, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context, inputs, batch_nodes)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\executor\\flow_executor.py\", line 1005, in _submit_to_scheduler\n    ).execute(self._line_timeout_sec)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\executor\\_flow_nodes_scheduler.py\", line 89, in execute\n    raise e\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\executor\\_flow_nodes_scheduler.py\", line 72, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\executor\\_flow_nodes_scheduler.py\", line 113, in _collect_outputs\n    each_node_result = each_future.result()\n  File \"C:\\git\\pfmisc\\.conda\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n    return self.__get_result()\n  File \"C:\\git\\pfmisc\\.conda\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"C:\\git\\pfmisc\\.conda\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\executor\\_flow_nodes_scheduler.py\", line 134, in _exec_single_node_in_thread\n    result = context.invoke_tool(node, f, kwargs=kwargs)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\_core\\flow_execution_context.py\", line 88, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f, kwargs)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\_core\\flow_execution_context.py\", line 196, in _invoke_tool_with_timer\n    raise e\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\_core\\flow_execution_context.py\", line 190, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\_core\\tracer.py\", line 528, in wrapped\n    output = func(*args, **kwargs)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\tools\\common.py\", line 222, in wrapper\n    raise WrappedOpenAIError(e)\n",
              "innerException": {
                "type": "BadRequestError",
                "message": "Error code: 400 - {'error': {'message': '3 validation errors for Request\\nbody -> stop\\n  none is not an allowed value (type=type_error.none.not_allowed)\\nbody -> logit_bias\\n  extra fields not permitted (type=value_error.extra)\\nbody -> response_format\\n  extra fields not permitted (type=value_error.extra)', 'type': 'invalid_request_error', 'param': None, 'code': None}}",
                "stackTrace": "Traceback (most recent call last):\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\tools\\common.py\", line 207, in wrapper\n    return func(*args, **kwargs)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\tools\\aoai.py\", line 157, in chat\n    completion = self._client.chat.completions.create(**params)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\_core\\openai_injector.py\", line 88, in wrapper\n    return f(*args, **kwargs)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\promptflow\\_core\\tracer.py\", line 528, in wrapped\n    output = func(*args, **kwargs)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n    return func(*args, **kwargs)\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 667, in create\n    return self._post(\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\openai\\_base_client.py\", line 1208, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\openai\\_base_client.py\", line 897, in request\n    return self._request(\n  File \"C:\\git\\pfmisc\\.conda\\lib\\site-packages\\openai\\_base_client.py\", line 988, in _request\n    raise self._make_status_error_from_response(err.response) from None\n",
                "innerException": null
              }
            }
          }
        }
      ],
      "variant_id": "",
      "name": "",
      "description": "",
      "tags": null,
      "system_metrics": {
        "duration": 1.86915,
        "prompt_tokens": 216,
        "completion_tokens": 19,
        "total_tokens": 235
      },
      "result": null,
      "upload_metrics": false
    }
  ],
  "node_runs": [
    {
      "node": "joke_score",
      "flow_run_id": "5992c219-66a4-4c28-beab-abafcff2a13c",
      "run_id": "5992c219-66a4-4c28-beab-abafcff2a13c_joke_score_0",
      "status": "Completed",
      "inputs": {
        "deployment_name": "gpt-4-32k-default-aueast",
        "temperature": 0.1,
        "top_p": 1,
        "max_tokens": 50,
        "presence_penalty": 0,
        "frequency_penalty": 0,
        "joke": "chickens",
        "topic": "What did the chicken cross the road? .. to get to the other side! "
      },
      "output": "{\n\"comedic_value\": 1,\n\"comedic_relevance\": 1\n}",
      "metrics": null,
      "error": null,
      "parent_run_id": "5992c219-66a4-4c28-beab-abafcff2a13c_0",
      "start_time": "2024-03-23T09:08:59.695946Z",
      "end_time": "2024-03-23T09:09:01.104014Z",
      "index": 0,
      "api_calls": [
        {
          "name": "AzureOpenAI.chat",
          "type": "Tool",
          "inputs": {
            "prompt": "System: \nYou are a dad jokes expert, you will review dad jokes against a given topic and assess how funny and on topic the joke is.\n\nYou will give the joke 1 to 5 star score based on comedic value: 1 is eh, 5 is super funny.\nAnd you will give the joke 1 to 5 star score based on joke relevance to topic, where 1 is remotely on topic, and 5 very on topic.\n\nThis rating value should always be an integer between 1 and 5. So the rating produced should be 1 or 2 or 3 or 4 or 5.\n\nHere is an example:\n\ntopic: chicken\njoke: why did the chicken cross the rod, to get to the other side\n\nExpected result in json format: \n\n{\n\"comedic_value\": 4,\n\"comedic_relevance\": 5\n}\n\n\nhere is the user input:\n\ntopic:  {{topic}}\njoke: {{joke}}",
            "deployment_name": "gpt-4-32k-default-aueast",
            "temperature": 0.1,
            "top_p": 1,
            "max_tokens": 50,
            "presence_penalty": 0,
            "frequency_penalty": 0,
            "joke": "chickens",
            "topic": "What did the chicken cross the road? .. to get to the other side! "
          },
          "output": "{\n\"comedic_value\": 1,\n\"comedic_relevance\": 1\n}",
          "start_time": 1711145339.696947,
          "end_time": 1711145341.098032,
          "error": null,
          "children": [
            {
              "name": "openai.resources.chat.completions.Completions.create",
              "type": "LLM",
              "inputs": {
                "model": "gpt-4-32k-default-aueast",
                "messages": [
                  {
                    "role": "system",
                    "content": "You are a dad jokes expert, you will review dad jokes against a given topic and assess how funny and on topic the joke is.\n\nYou will give the joke 1 to 5 star score based on comedic value: 1 is eh, 5 is super funny.\nAnd you will give the joke 1 to 5 star score based on joke relevance to topic, where 1 is remotely on topic, and 5 very on topic.\n\nThis rating value should always be an integer between 1 and 5. So the rating produced should be 1 or 2 or 3 or 4 or 5.\n\nHere is an example:\n\ntopic: chicken\njoke: why did the chicken cross the rod, to get to the other side\n\nExpected result in json format: \n\n{\n\"comedic_value\": 4,\n\"comedic_relevance\": 5\n}\n\n\nhere is the user input:\n\ntopic:  What did the chicken cross the road? .. to get to the other side! \njoke: chickens"
                  }
                ],
                "temperature": 0.1,
                "top_p": 1,
                "n": 1,
                "stream": false,
                "stop": null,
                "max_tokens": 50,
                "presence_penalty": 0,
                "frequency_penalty": 0,
                "logit_bias": {},
                "user": "",
                "response_format": null
              },
              "output": {
                "id": "chatcmpl-95rf1PYYiDGQJaqiBi5EVgEirMhH1",
                "choices": [
                  {
                    "finish_reason": "stop",
                    "index": 0,
                    "logprobs": null,
                    "message": {
                      "content": "{\n\"comedic_value\": 1,\n\"comedic_relevance\": 1\n}",
                      "role": "assistant",
                      "function_call": null,
                      "tool_calls": null
                    },
                    "content_filter_results": {
                      "hate": {
                        "filtered": false,
                        "severity": "safe"
                      },
                      "self_harm": {
                        "filtered": false,
                        "severity": "safe"
                      },
                      "sexual": {
                        "filtered": false,
                        "severity": "safe"
                      },
                      "violence": {
                        "filtered": false,
                        "severity": "safe"
                      }
                    }
                  }
                ],
                "created": 1711184939,
                "model": "gpt-4-32k",
                "object": "chat.completion",
                "system_fingerprint": null,
                "usage": {
                  "completion_tokens": 19,
                  "prompt_tokens": 216,
                  "total_tokens": 235
                },
                "prompt_filter_results": [
                  {
                    "prompt_index": 0,
                    "content_filter_results": {
                      "hate": {
                        "filtered": false,
                        "severity": "safe"
                      },
                      "self_harm": {
                        "filtered": false,
                        "severity": "safe"
                      },
                      "sexual": {
                        "filtered": false,
                        "severity": "safe"
                      },
                      "violence": {
                        "filtered": false,
                        "severity": "safe"
                      }
                    }
                  }
                ]
              },
              "start_time": 1711145339.700947,
              "end_time": 1711145341.097014,
              "error": null,
              "children": [],
              "node_name": null,
              "parent_id": "772a551a-16dd-4e5a-91b7-7525c7c4014c",
              "id": "b241652b-9007-451d-a943-3c3eaf2e6364",
              "system_metrics": {
                "completion_tokens": 19,
                "prompt_tokens": 216,
                "total_tokens": 235
              }
            }
          ],
          "node_name": "joke_score",
          "parent_id": "",
          "id": "772a551a-16dd-4e5a-91b7-7525c7c4014c",
          "system_metrics": {
            "completion_tokens": 19,
            "prompt_tokens": 216,
            "total_tokens": 235
          }
        }
      ],
      "variant_id": "",
      "cached_run_id": null,
      "cached_flow_run_id": null,
      "logs": {
        "stdout": "",
        "stderr": ""
      },
      "system_metrics": {
        "completion_tokens": 19,
        "prompt_tokens": 216,
        "total_tokens": 235,
        "duration": 1.408068
      },
      "result": "{\n\"comedic_value\": 1,\n\"comedic_relevance\": 1\n}"
    },
    {
      "node": "line_process",
      "flow_run_id": "5992c219-66a4-4c28-beab-abafcff2a13c",
      "run_id": "5992c219-66a4-4c28-beab-abafcff2a13c_line_process_0",
      "status": "Completed",
      "inputs": {
        "jokescore": "{\n\"comedic_value\": 1,\n\"comedic_relevance\": 1\n}"
      },
      "output": {
        "comedic_value": 1,
        "comedic_value_pass_rate": 0,
        "comedic_relevance": 1,
        "comedic_relevance_pass_rate": 0
      },
      "metrics": null,
      "error": null,
      "parent_run_id": "5992c219-66a4-4c28-beab-abafcff2a13c_0",
      "start_time": "2024-03-23T09:09:01.109014Z",
      "end_time": "2024-03-23T09:09:01.116019Z",
      "index": 0,
      "api_calls": [
        {
          "name": "line_process",
          "type": "Tool",
          "inputs": {
            "jokescore": "{\n\"comedic_value\": 1,\n\"comedic_relevance\": 1\n}"
          },
          "output": {
            "comedic_value": 1,
            "comedic_value_pass_rate": 0,
            "comedic_relevance": 1,
            "comedic_relevance_pass_rate": 0
          },
          "start_time": 1711145341.110026,
          "end_time": 1711145341.114015,
          "error": null,
          "children": [],
          "node_name": "line_process",
          "parent_id": "",
          "id": "d488766e-dd47-469f-8004-12ac04ffb60a",
          "system_metrics": {}
        }
      ],
      "variant_id": "",
      "cached_run_id": null,
      "cached_flow_run_id": null,
      "logs": {
        "stdout": "",
        "stderr": ""
      },
      "system_metrics": {
        "duration": 0.007005
      },
      "result": {
        "comedic_value": 1,
        "comedic_value_pass_rate": 0,
        "comedic_relevance": 1,
        "comedic_relevance_pass_rate": 0
      }
    },
    {
      "node": "ensure_json",
      "flow_run_id": "c92cbdb0-385b-4b07-a635-de247f82d612",
      "run_id": "c92cbdb0-385b-4b07-a635-de247f82d612_ensure_json_86e91a09-463a-41c7-9123-a202b9c76334",
      "status": "Completed",
      "inputs": {
        "deployment_name": "gpt-4-32k-default-aueast",
        "temperature": 0,
        "top_p": 1,
        "max_tokens": 50,
        "presence_penalty": 0,
        "frequency_penalty": 0,
        "input": "{\n\"comedic_value\": 1,\n\"comedic_relevance\": 1\n}"
      },
      "output": "The provided string is in correct JSON format.",
      "metrics": null,
      "error": null,
      "parent_run_id": "c92cbdb0-385b-4b07-a635-de247f82d612",
      "start_time": "2024-03-23T09:09:58.919105Z",
      "end_time": "2024-03-23T09:09:59.754256Z",
      "index": null,
      "api_calls": [
        {
          "name": "AzureOpenAI.chat",
          "type": "Tool",
          "inputs": {
            "prompt": "System:\nensure the following is a correct json format: \n\nuser input:\n{{input}}",
            "deployment_name": "gpt-4-32k-default-aueast",
            "temperature": 0,
            "top_p": 1,
            "max_tokens": 50,
            "presence_penalty": 0,
            "frequency_penalty": 0,
            "input": "{\n\"comedic_value\": 1,\n\"comedic_relevance\": 1\n}"
          },
          "output": "The provided string is in correct JSON format.",
          "start_time": 1711145398.919363,
          "end_time": 1711145399.748253,
          "error": null,
          "children": [
            {
              "name": "openai.resources.chat.completions.Completions.create",
              "type": "LLM",
              "inputs": {
                "model": "gpt-4-32k-default-aueast",
                "messages": [
                  {
                    "role": "system",
                    "content": "ensure the following is a correct json format: \n\nuser input:\n{\n\"comedic_value\": 1,\n\"comedic_relevance\": 1\n}"
                  }
                ],
                "temperature": 0,
                "top_p": 1,
                "n": 1,
                "stream": false,
                "stop": null,
                "max_tokens": 50,
                "presence_penalty": 0,
                "frequency_penalty": 0,
                "logit_bias": {},
                "user": "",
                "response_format": null
              },
              "output": {
                "id": "chatcmpl-95rfze2DWxEPBzSuhIVtPQWoND45U",
                "choices": [
                  {
                    "finish_reason": "stop",
                    "index": 0,
                    "logprobs": null,
                    "message": {
                      "content": "The provided string is in correct JSON format.",
                      "role": "assistant",
                      "function_call": null,
                      "tool_calls": null
                    },
                    "content_filter_results": {
                      "hate": {
                        "filtered": false,
                        "severity": "safe"
                      },
                      "self_harm": {
                        "filtered": false,
                        "severity": "safe"
                      },
                      "sexual": {
                        "filtered": false,
                        "severity": "safe"
                      },
                      "violence": {
                        "filtered": false,
                        "severity": "safe"
                      }
                    }
                  }
                ],
                "created": 1711184999,
                "model": "gpt-4-32k",
                "object": "chat.completion",
                "system_fingerprint": null,
                "usage": {
                  "completion_tokens": 9,
                  "prompt_tokens": 39,
                  "total_tokens": 48
                },
                "prompt_filter_results": [
                  {
                    "prompt_index": 0,
                    "content_filter_results": {
                      "hate": {
                        "filtered": false,
                        "severity": "safe"
                      },
                      "self_harm": {
                        "filtered": false,
                        "severity": "safe"
                      },
                      "sexual": {
                        "filtered": false,
                        "severity": "safe"
                      },
                      "violence": {
                        "filtered": false,
                        "severity": "safe"
                      }
                    }
                  }
                ]
              },
              "start_time": 1711145398.923374,
              "end_time": 1711145399.748253,
              "error": null,
              "children": [],
              "node_name": null,
              "parent_id": "989f331e-bab0-4a45-81a2-ab782e484b1e",
              "id": "93f643d7-685c-4abc-9ec8-091b2eef39b7",
              "system_metrics": {
                "completion_tokens": 9,
                "prompt_tokens": 39,
                "total_tokens": 48
              }
            }
          ],
          "node_name": "ensure_json",
          "parent_id": "",
          "id": "989f331e-bab0-4a45-81a2-ab782e484b1e",
          "system_metrics": {
            "completion_tokens": 9,
            "prompt_tokens": 39,
            "total_tokens": 48
          }
        }
      ],
      "variant_id": "",
      "cached_run_id": null,
      "cached_flow_run_id": null,
      "logs": {
        "stdout": "",
        "stderr": ""
      },
      "system_metrics": {
        "completion_tokens": 9,
        "prompt_tokens": 39,
        "total_tokens": 48,
        "duration": 0.835151
      },
      "result": "The provided string is in correct JSON format."
    }
  ]
}